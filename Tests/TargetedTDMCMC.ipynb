{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199501c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the thread used by numpy for better parallelization\n",
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee25a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Triangle.Constants import *\n",
    "from Triangle.FFTTools import *\n",
    "from Triangle.Noise import *\n",
    "from Triangle.Orbit import *\n",
    "from Triangle.Data import *\n",
    "from Triangle.Interferometer import *\n",
    "from Triangle.TDI import *\n",
    "from Triangle.Glitch import *\n",
    "from Triangle.GW import *\n",
    "from Triangle.Cosmology import LuminosityDistance, z_dl\n",
    "\n",
    "from Triangle_BBH.Utils import ParamArr2ParamDict, ParamDict2ParamArr\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.rcParams['text.usetex'] = True\n",
    "# matplotlib.rcParams['font.family'] = 'serif'\n",
    "\n",
    "import multiprocessing\n",
    "if __name__ == \"__main__\":\n",
    "    multiprocessing.set_start_method(\"fork\")\n",
    "print(\"number of cpus =\", multiprocessing.cpu_count())\n",
    "# pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a555c2e",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5filename = \"/Users/taijidatacenter/workspace/TDCII_Data/2_2_MBHB_PhenomT_TDIXYZ.h5\"\n",
    "with h5py.File(h5filename, \"r\") as h5file:\n",
    "    data_dict = read_dict_from_h5(h5file[\"/\"])\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5filename = \"/Users/taijidatacenter/workspace/TDCII_Data/MBHB_PhenomT_parameters.h5\"\n",
    "with h5py.File(h5filename, \"r\") as h5file:\n",
    "    param_dict = read_dict_from_h5(h5file[\"/\"])\n",
    "param_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict[\"coalescence_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a76abe8",
   "metadata": {},
   "source": [
    "## Search settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dea166",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = 349.5 * DAY \n",
    "Tobs = 1 * DAY \n",
    "t_end = t_start + Tobs \n",
    "\n",
    "time_idx = np.where((data_dict[\"time\"] >= t_start)&(data_dict[\"time\"] <= t_end))[0]\n",
    "data_time = data_dict[\"time\"][time_idx]\n",
    "dt = data_time[1] - data_time[0]\n",
    "channel_names = list(data_dict[\"XYZ\"].keys())\n",
    "data_channels_td = np.array([data_dict[\"XYZ\"][ch][time_idx] for ch in channel_names])\n",
    "print(data_time.shape, data_channels_td.shape)\n",
    "\n",
    "data_channels_fd = []\n",
    "FT_args = dict(fsample=1./dt, window_type=\"tukey\", window_args_dict=dict(alpha=0.05))\n",
    "for i in range(3):\n",
    "    ff, xf = FFT_window(data_channels_td[i], **FT_args)\n",
    "    data_channels_fd.append(xf)\n",
    "data_frequency = ff.copy()\n",
    "data_channels_fd = np.array(data_channels_fd)\n",
    "\n",
    "mask = np.ones_like(data_frequency, dtype=bool)\n",
    "for i in range(1, 41):\n",
    "    mask_idx = np.where(np.abs(data_frequency - i*0.025)<i*3e-4)[0]\n",
    "    mask[mask_idx] = False \n",
    "data_frequency = data_frequency[mask]\n",
    "data_channels_fd = data_channels_fd[:, mask]\n",
    "print(data_frequency.shape, data_channels_fd.shape)\n",
    "\n",
    "a_tmp, e_tmp, t_tmp = AETfromXYZ(X=data_channels_fd[0], Y=data_channels_fd[1], Z=data_channels_fd[2])\n",
    "data_channels_opt_fd = np.array([a_tmp, e_tmp, t_tmp])\n",
    "channel_names_opt = [\"A2\", \"E2\", \"T2\"]\n",
    "\n",
    "orbit = Orbit(OrbitDir=\"../OrbitData/MicroSateOrbitEclipticTCB\")\n",
    "PSDfunc = TDIPSDs()\n",
    "arms = dict()\n",
    "for key in MOSA_labels: \n",
    "    arms[key] = orbit.LTTfunctions()[key]((t_end+t_start)/2.)\n",
    "arms = MOSADict(arms)\n",
    "data_psd_opt = np.array([\n",
    "    PSDfunc.PSD_A2_unequal(data_frequency, arms), \n",
    "    PSDfunc.PSD_E2_unequal(data_frequency, arms), \n",
    "    PSDfunc.PSD_T2_unequal(data_frequency, arms), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a2667",
   "metadata": {},
   "source": [
    "## Signal generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_idx = np.where((param_dict[\"coalescence_time\"]>t_start/DAY)&(param_dict[\"coalescence_time\"]<=t_end/DAY))[0]\n",
    "mbhb_parameters = dict() \n",
    "for k, v in param_dict.items(): \n",
    "    mbhb_parameters[k] = v[source_idx][0]\n",
    "mbhb_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "approx = \"IMRPhenomT\"\n",
    "\n",
    "mbhb_waveform_generator = MBHB_Injection(approx_method=approx, buffer=True)\n",
    "mbhb_response_generator = FastMichelsonTDIResponse(\n",
    "    orbit=orbit, \n",
    "    tcb_times=data_time.copy(), \n",
    "    use_gpu=False, \n",
    "    drop_points=int(1000./dt), \n",
    "    interp_method=\"Spline5\",  # use a safe interp order to ensure accuracy \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_generator_fd(params): \n",
    "    res_a, res_e, res_t = mbhb_response_generator(parameters=params, waveform_generator=mbhb_waveform_generator, optimal_combination=True)\n",
    "    _, res_af = FFT_window(res_a, **FT_args)\n",
    "    _, res_ef = FFT_window(res_e, **FT_args)\n",
    "    _, res_tf = FFT_window(res_t, **FT_args)\n",
    "    res_aetf = np.array([res_af, res_ef, res_tf])\n",
    "    return res_aetf[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f583589",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_channels_fd = signal_generator_fd(mbhb_parameters)\n",
    "model_channels_fd.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa08365",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = dict(A2=GREEN1, E2=RED, T2=BLUE)\n",
    "for ich, nch in enumerate(channel_names_opt):\n",
    "    plt.loglog(data_frequency, np.abs(data_channels_opt_fd[ich]), label=nch, linewidth=1, color=color_dict[nch], alpha=0.5)\n",
    "    plt.loglog(data_frequency, np.abs(model_channels_fd[ich]), color=color_dict[nch])\n",
    "    plt.loglog(data_frequency, np.sqrt(data_psd_opt[ich] * Tobs / 2.), linestyle=\"--\", color=color_dict[nch])\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"FD TDI (1/Hz)\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim(1e-23,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da841243",
   "metadata": {},
   "source": [
    "## Likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ab70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike(params): \n",
    "    p = ParamArr2ParamDict(params)\n",
    "    tmp_channels_fd = signal_generator_fd(p) # (3, Nf)\n",
    "    return -2.  / Tobs * np.sum(np.abs(data_channels_opt_fd - tmp_channels_fd) ** 2 / data_psd_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46784371",
   "metadata": {},
   "source": [
    "## MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fdfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eryn.ensemble import EnsembleSampler\n",
    "from eryn.state import State\n",
    "from eryn.prior import ProbDistContainer, uniform_dist\n",
    "from eryn.utils import TransformContainer\n",
    "from eryn.moves import GaussianMove, StretchMove, CombineMove\n",
    "from eryn.utils.utility import groups_from_inds\n",
    "from eryn.backends import HDFBackend\n",
    "from eryn.utils import SearchConvergeStopping\n",
    "\n",
    "from corner import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r\"${\\rm lg}\\mathcal{M}_{c,z}$\", r\"$q$\", r\"$\\chi_{z,1}$\", r\"$\\chi_{z,2}$\", r\"$t_c$\", r\"$\\varphi_c$\", r\"${\\rm lg} D_L$\", r\"$\\cos \\iota$\", r\"$\\lambda$\", r\"$\\sin \\beta$\", r\"$\\psi$\"]\n",
    "\n",
    "truths = ParamDict2ParamArr(mbhb_parameters)\n",
    "\n",
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyper parameters\n",
    "ndim = 11 # dimension of paramters \n",
    "nwalkers = 100 # number of random walkers, limited by the vRAM of my 4080S, use fewer to speed up and more (e.g. 400) to get more smooth posterior \n",
    "ntemps = 4 # number of temperatures used in parallel tempering \n",
    "temps = np.array(list(np.power(2., np.arange(ntemps - 1))) + [np.infty]) \n",
    "betas = 1. / temps \n",
    "tempering_kwargs=dict(betas=betas)\n",
    "\n",
    "mcmc_moves = StretchMove(a=2) # emcee move \n",
    "\n",
    "stop = None \n",
    "\n",
    "# set priors \n",
    "\n",
    "# # (1) a broad prior \n",
    "# lim_lgMc = [5.5, 6.5]\n",
    "# lim_q = [0.1, 0.999]\n",
    "# lim_chiz1 = [-0.99, 0.99]\n",
    "# lim_chiz2 = [-0.99, 0.99]\n",
    "# lim_tc = [fiducial_parameters[\"coalescence_time\"] - 500/DAY, fiducial_parameters[\"coalescence_time\"] + 500/DAY] # assume a preliminary search step to locate the merger within 1000s\n",
    "# lim_phic = [0, TWOPI]\n",
    "# lim_lgD = [3.5, 5.5]\n",
    "# lim_cosinc = [-1, 1]\n",
    "# lim_lam = [0, TWOPI]\n",
    "# lim_sinbeta = [-1, 1]\n",
    "# lim_psi = [0, PI]\n",
    "\n",
    "# (2) a narrow prior \n",
    "lim_lgMc = [truths[0] - 1e-1, truths[0] + 1e-1]\n",
    "lim_q = [max(0., truths[1] - 3e-1), min(1., truths[1] + 3e-1)]\n",
    "# lim_chiz1 = [max(-0.99, truths[2] - 5e-1), min(0.99, truths[2] + 5e-1)]\n",
    "# lim_chiz2 = [max(-0.99, truths[3] - 5e-1), min(0.99, truths[3] + 5e-1)]\n",
    "lim_chiz1 = [-0.99, 0.99]\n",
    "lim_chiz2 = [-0.99, 0.99]\n",
    "lim_tc = [truths[4] - 1000/DAY, truths[4] + 1000/DAY] # assume a preliminary search step to locate the merger within 1000s\n",
    "lim_phic = [0, TWOPI]\n",
    "lim_lgD = [4.5, 5.5]\n",
    "lim_cosinc = [-1, 1]\n",
    "lim_lam = [0, TWOPI]\n",
    "lim_sinbeta = [-1, 1]\n",
    "lim_psi = [0, PI]\n",
    "\n",
    "lims = np.array([lim_lgMc, lim_q, lim_chiz1, lim_chiz2, lim_tc, lim_phic, lim_lgD, lim_cosinc, lim_lam, lim_sinbeta, lim_psi])\n",
    "lower_lims = lims[:, 0]\n",
    "upper_lims = lims[:, 1]\n",
    "\n",
    "priors_in = {i: uniform_dist(lims[i][0], lims[i][1]) for i in range(ndim)}\n",
    "priors = ProbDistContainer(priors_in)\n",
    "priors.use_cupy = False\n",
    "\n",
    "# set starting range \n",
    "start_lims = np.array(truths)[:, np.newaxis] + np.array([-1e-3, 1e-3])\n",
    "start_priors_in = {i: uniform_dist(start_lims[i][0], start_lims[i][1]) for i in range(ndim)}\n",
    "start_priors = ProbDistContainer(start_priors_in)\n",
    "start_priors.use_cupy = False\n",
    "\n",
    "lims, start_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcdfee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "\n",
    "ensemble = EnsembleSampler(\n",
    "    nwalkers,\n",
    "    ndim,\n",
    "    loglike, \n",
    "    priors,\n",
    "    args=[],\n",
    "    tempering_kwargs=tempering_kwargs,\n",
    "    stopping_fn=stop,\n",
    "    stopping_iterations=10,\n",
    "    moves=mcmc_moves,\n",
    "    vectorize=False,\n",
    "    pool=pool, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize starting positions throughout prior\n",
    "coords = start_priors.rvs(size=(ntemps, nwalkers,))\n",
    "\n",
    "thin_by = 100 \n",
    "burn = 0\n",
    "nsteps = int(100000 / thin_by) # should be more than enough \n",
    "\n",
    "ensemble.stopping_fn = None\n",
    "\n",
    "out = ensemble.run_mcmc(coords, nsteps, burn=burn, progress=True, thin_by=thin_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf59f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thin = 1\n",
    "burnin = 0\n",
    "len_chain = len(ensemble.get_chain(thin=thin, discard=burnin)['model_0'][:, 0, 0, :, 0])\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(ndim, 1)\n",
    "fig.set_size_inches(10, 3*ndim)\n",
    "for i in range(ndim):     \n",
    "    for walk in range(20): # plot 20 walkers \n",
    "        ax[i].plot(ensemble.get_chain(thin=thin, discard=burnin)['model_0'][:, 0, walk, 0, i])\n",
    "        ax[i].hlines(truths[i], 0, len_chain, color='k', linestyle='-.', linewidth=0.8)\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "# plt.savefig(\"MCMC_trajectory_full.jpg\", dpi=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=80 # currently the number of burn-in steps is only set by monitoring the walkers. It should be more automatic for practical uses.\n",
    "thin = 10\n",
    "\n",
    "samp = ensemble.get_chain(discard=burnin, thin=thin)['model_0'][:, 0, :, :, :].reshape(-1, ndim)\n",
    "print(\"sample shape:\", samp.shape)\n",
    "\n",
    "plt.figure()\n",
    "corner(\n",
    "    samp, bins=50, color=BLUE, \n",
    "    labels=labels, label_kwargs={'fontsize': 14}, \n",
    "    range=lims,\n",
    "    truths=truths, truth_color=RED, \n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True, title_kwargs={'fontsize':14},\n",
    "    levels = (1. - np.exp(-1.**2/2), 1. - np.exp(-2.**2/2), 1. - np.exp(-3.**2/2)),\n",
    "    smooth=0.9, # default for bilby: smooth = 0.9, bins = 50 \n",
    "    plot_density=True, # whether to show the density of samples with colors \n",
    "    plot_datapoints=False, # whether to plot individual data points \n",
    "    fill_contours=True, # whether to fill the corners \n",
    "    );\n",
    "# plt.savefig(\"MCMC_corner_full.jpg\", dpi=360)\n",
    "# np.save(\"chain_full.npy\", samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63b207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
